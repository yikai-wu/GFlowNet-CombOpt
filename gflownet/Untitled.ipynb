{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9968613-b1da-4f68-b6ab-9b8f2b39e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import gzip, pickle\n",
    "from time import time, sleep\n",
    "from tqdm import tqdm\n",
    "import hydra\n",
    "from omegaconf import DictConfig, open_dict, OmegaConf\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import dgl\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "from data import get_data_loaders\n",
    "from util import seed_torch, TransitionBuffer, get_mdp_class\n",
    "from algorithm import DetailedBalanceTransitionBuffer\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6ae6ddf-f1cf-4e44-9bcc-9b18ff618923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alg_buffer(cfg, device):\n",
    "    assert cfg.alg in [\"db\", \"fl\"]\n",
    "    buffer = TransitionBuffer(cfg.tranbuff_size, cfg)\n",
    "    alg = DetailedBalanceTransitionBuffer(cfg, device)\n",
    "    return alg, buffer\n",
    "\n",
    "def get_logr_scaler(cfg, process_ratio=1., reward_exp=None):\n",
    "    if reward_exp is None:\n",
    "        reward_exp = float(cfg.reward_exp)\n",
    "\n",
    "    if cfg.anneal == \"linear\":\n",
    "        process_ratio = max(0., min(1., process_ratio)) # from 0 to 1\n",
    "        reward_exp = reward_exp * process_ratio +\\\n",
    "                     float(cfg.reward_exp_init) * (1 - process_ratio)\n",
    "    elif cfg.anneal == \"none\":\n",
    "        pass\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # (R/T)^beta -> (log R - log T) * beta\n",
    "    def logr_scaler(sol_size, gbatch=None):\n",
    "        logr = sol_size\n",
    "        return logr * reward_exp\n",
    "    return logr_scaler\n",
    "\n",
    "def refine_cfg(cfg):\n",
    "    with open_dict(cfg):\n",
    "        cfg.device = cfg.d\n",
    "        cfg.work_directory = os.getcwd()\n",
    "\n",
    "        if cfg.task in [\"mis\", \"maxindset\", \"maxindependentset\",]:\n",
    "            cfg.task = \"MaxIndependentSet\"\n",
    "            cfg.wandb_project_name = \"MIS\"\n",
    "        elif cfg.task in [\"mds\", \"mindomset\", \"mindominateset\",]:\n",
    "            cfg.task = \"MinDominateSet\"\n",
    "            cfg.wandb_project_name = \"MDS\"\n",
    "        elif cfg.task in [\"mc\", \"maxclique\",]:\n",
    "            cfg.task = \"MaxClique\"\n",
    "            cfg.wandb_project_name = \"MaxClique\"\n",
    "        elif cfg.task in [\"mcut\", \"maxcut\",]:\n",
    "            cfg.task = \"MaxCut\"\n",
    "            cfg.wandb_project_name = \"MaxCut\"\n",
    "        elif cfg.task in [\"color\", \"coloring\", \"Coloring\"]:\n",
    "            cfg.task = \"Coloring\"\n",
    "            cfg.wandb_project_name = \"Coloring\"\n",
    "        elif cfg.task in [\"3color\", \"3coloring\", \"threecoloring\", \"ThreeColoring\"]:\n",
    "            cfg.task = \"ThreeColoring\"\n",
    "            cfg.wandb_project_name = \"ThreeColoring\"\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # architecture\n",
    "        assert cfg.arch in [\"gin\"]\n",
    "\n",
    "        # log reward shape\n",
    "        cfg.reward_exp = cfg.rexp\n",
    "        cfg.reward_exp_init = cfg.rexpit\n",
    "        if cfg.anneal in [\"lin\"]:\n",
    "            cfg.anneal = \"linear\"\n",
    "\n",
    "        # training\n",
    "        cfg.batch_size = cfg.bs\n",
    "        cfg.batch_size_interact = cfg.bsit\n",
    "        cfg.leaf_coef = cfg.lc\n",
    "        cfg.same_graph_across_batch = cfg.sameg\n",
    "\n",
    "        # data\n",
    "        cfg.test_batch_size = cfg.tbs\n",
    "        if \"rb\" in cfg.input:\n",
    "            cfg.data_type = cfg.input.upper()\n",
    "        elif \"ba\" in cfg.input:\n",
    "            cfg.data_type = cfg.input.upper()\n",
    "        elif \"partition\" in cfg.input:\n",
    "            cfg.data_type = cfg.input.upper()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    del cfg.d, cfg.rexp, cfg.rexpit, cfg.bs, cfg.bsit, cfg.lc, cfg.sameg, cfg.tbs\n",
    "    return cfg\n",
    "\n",
    "@torch.no_grad()\n",
    "def rollout(gbatch, cfg, alg):\n",
    "    env = get_mdp_class(cfg.task)(gbatch, cfg)\n",
    "    state = env.state\n",
    "\n",
    "    ##### sample traj\n",
    "    reward_exp_eval = None\n",
    "    traj_s, traj_r, traj_a, traj_d = [], [], [], []\n",
    "    while not all(env.done):\n",
    "        action = alg.sample(gbatch, state, env.done, rand_prob=cfg.randp, reward_exp=reward_exp_eval)\n",
    "\n",
    "        traj_s.append(state)\n",
    "        traj_r.append(env.get_log_reward())\n",
    "        traj_a.append(action)\n",
    "        traj_d.append(env.done)\n",
    "        state = env.step(action)\n",
    "\n",
    "    ##### save last state\n",
    "    traj_s.append(state)\n",
    "    traj_r.append(env.get_log_reward())\n",
    "    traj_d.append(env.done)\n",
    "    assert len(traj_s) == len(traj_a) + 1 == len(traj_r) == len(traj_d)\n",
    "\n",
    "    traj_s = torch.stack(traj_s, dim=1) # (sum of #node per graph in batch, max_traj_len)\n",
    "    traj_r = torch.stack(traj_r, dim=1) # (batch_size, max_traj_len)\n",
    "    traj_a = torch.stack(traj_a, dim=1) # (batch_size, max_traj_len-1)\n",
    "    \"\"\"\n",
    "    traj_a is tensor like \n",
    "    [ 4, 30, 86, 95, 96, 29, -1, -1],\n",
    "    [47, 60, 41, 11, 55, 64, 80, -1],\n",
    "    [26, 38, 13,  5,  9, -1, -1, -1]\n",
    "    \"\"\"\n",
    "    traj_d = torch.stack(traj_d, dim=1) # (batch_size, max_traj_len)\n",
    "    \"\"\"\n",
    "    traj_d is tensor like \n",
    "    [False, False, False, False, False, False,  True,  True,  True],\n",
    "    [False, False, False, False, False, False, False,  True,  True],\n",
    "    [False, False, False, False, False,  True,  True,  True,  True]\n",
    "    \"\"\"\n",
    "    traj_len = 1 + torch.sum(~traj_d, dim=1) # (batch_size, )\n",
    "\n",
    "    ##### graph, state, action, done, reward, trajectory length\n",
    "    batch = gbatch.cpu(), traj_s.cpu(), traj_a.cpu(), traj_d.cpu(), traj_r.cpu(), traj_len.cpu()\n",
    "    return batch, env.batch_metric(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccc88d47-5e4f-4a32-ab6e-5b9ae4552943",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hydra.main(config_path=\"configs\", config_name=\"main\") # for hydra-core==1.1.0\n",
    "# @hydra.main(version_base=None, config_path=\"configs\", config_name=\"main\") # for newer hydra\n",
    "def main(cfg: DictConfig):\n",
    "    cfg = refine_cfg(cfg)\n",
    "    device = torch.device(f\"cuda:{cfg.device:d}\" if torch.cuda.is_available() and cfg.device>=0 else \"cpu\")\n",
    "    print(f\"Device: {device}\")\n",
    "    alg, buffer = get_alg_buffer(cfg, device)\n",
    "    seed_torch(cfg.seed)\n",
    "    print(str(cfg))\n",
    "    print(f\"Work directory: {os.getcwd()}\")\n",
    "\n",
    "    train_loader, test_loader = get_data_loaders(cfg)\n",
    "    trainset_size = len(train_loader.dataset)\n",
    "    print(f\"Trainset size: {trainset_size}\")\n",
    "    alg_save_path = os.path.abspath(\"./alg.pt\")\n",
    "    alg_save_path_best = os.path.abspath(\"./alg_best.pt\")\n",
    "    train_data_used = 0\n",
    "    train_step = 0\n",
    "    train_logr_scaled_ls = []\n",
    "    train_metric_ls = []\n",
    "    metric_best = 0.\n",
    "    result = {\"set_size\": {}, \"logr_scaled\": {}, \"train_data_used\": {}, \"train_step\": {}, }\n",
    "    alg.load(\"C:\\\\Users\\\\IUmplt\\\\GitHub\\\\GFlowNet-CombOpt\\\\gflownet\\\\outputs\\\\2024.02.06\\\\05.20.15\\\\alg.pt\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(ep, train_step, train_data_used, logr_scaler):\n",
    "        torch.cuda.empty_cache()\n",
    "        num_repeat = 20\n",
    "        mis_ls, mis_top20_ls = [], []\n",
    "        logr_ls = []\n",
    "        pbar = tqdm(enumerate(test_loader))\n",
    "        pbar.set_description(f\"Test Epoch {ep:2d} Data used {train_data_used:5d}\")\n",
    "        for batch_idx, gbatch in pbar:\n",
    "            gbatch = gbatch.to(device)\n",
    "            gbatch_rep = dgl.batch([gbatch] * num_repeat)\n",
    "\n",
    "            env = get_mdp_class(cfg.task)(gbatch_rep, cfg)\n",
    "            state = env.state\n",
    "            while not all(env.done):\n",
    "                action = alg.sample(gbatch_rep, state, env.done, rand_prob=0.)\n",
    "                state = env.step(action)\n",
    "\n",
    "            logr_rep = logr_scaler(env.get_log_reward())\n",
    "            logr_ls += logr_rep.tolist()\n",
    "            curr_mis_rep = torch.tensor(env.batch_metric(state))\n",
    "            curr_mis_rep = rearrange(curr_mis_rep, \"(rep b) -> b rep\", rep=num_repeat).float()\n",
    "            print(curr_mis_rep)\n",
    "            mis_ls += curr_mis_rep.mean(dim=1).tolist()\n",
    "            mis_top20_ls += curr_mis_rep.max(dim=1)[0].tolist()\n",
    "            pbar.set_postfix({\"Metric\": f\"{np.mean(mis_ls):.2f}+-{np.std(mis_ls):.2f}\"})\n",
    "\n",
    "        print(f\"Test Epoch{ep:2d} Data used{train_data_used:5d}: \"\n",
    "              f\"Metric={np.mean(mis_ls):.2f}+-{np.std(mis_ls):.2f}, \"\n",
    "              f\"top20={np.mean(mis_top20_ls):.2f}, \"\n",
    "              f\"LogR scaled={np.mean(logr_ls):.2e}+-{np.std(logr_ls):.2e}\")\n",
    "\n",
    "        result[\"set_size\"][ep] = np.mean(mis_ls)\n",
    "        result[\"logr_scaled\"][ep] = np.mean(logr_ls)\n",
    "        result[\"train_step\"][ep] = train_step\n",
    "        result[\"train_data_used\"][ep] = train_data_used\n",
    "        pickle.dump(result, gzip.open(\"./result.json\", 'wb'))\n",
    "\n",
    "    evaluate(cfg.epochs, train_step, train_data_used, logr_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83738522-7aba-4524-b68a-0b6eb6bbf80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [--help] [--hydra-help] [--version]\n",
      "                             [--cfg {job,hydra,all}] [--resolve]\n",
      "                             [--package PACKAGE] [--run] [--multirun]\n",
      "                             [--shell-completion] [--config-path CONFIG_PATH]\n",
      "                             [--config-name CONFIG_NAME]\n",
      "                             [--config-dir CONFIG_DIR]\n",
      "                             [--info [{all,config,defaults,defaults-tree,plugins,searchpath}]]\n",
      "                             [overrides ...]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1677c01-200d-464a-8852-1bbcece255fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
